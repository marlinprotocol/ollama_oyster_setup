services:
  # http proxy service
  http_proxy:
    image: kalpita888/ollama_amd64:0.0.1
    container_name: http_proxy
    init: true
    network_mode: host
    volumes:
      - /app/ecdsa.sec:/app/secp.sec

  # Ollama service
  ollama_server:
    image: ollama/ollama:latest
    container_name: ollama_server
    init: true
    network_mode: host
    environment:
      - HOME=/root
      - TMPDIR=/app/ollamatmp/
    healthcheck:
      test: ["CMD-SHELL", "ollama --version"]
      interval: 10s
      retries: 3

  # Ollama model run
  ollama_model:
    image: ollama/ollama:latest
    container_name: ollama_model_llama3.2
    command: pull llama3.2
    init: true
    network_mode: host
    environment:
      - HOME=/root
      - TMPDIR=/app/ollamatmp/
    depends_on:
      ollama_server:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "ollama show llama3.2"]
      start_period: 2m30s
      interval: 30s
      retries: 3